{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dwdm08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eswar-11/DWDM/blob/main/dwdm08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cib84UNz9PDz"
      },
      "source": [
        "**1)**\n",
        "Develop a python code to generate frequent item setsusing Apriorialgorithmwith minimum\n",
        "support is 3. Consider the following\n",
        "transactions:((\"a\",\"b\",\"c\"),(\"a\",\"b\"),(\"a\",\"b\",\"d\"),(\"b\",\"e\"),(\"b\",\"c\",\"e\"),(\"a\",\"d\",\"e\"),(\"\n",
        "a\",\"c\"),(\"a\",\"b\",\"d\"),(\"c\",\"e\"),(\"a\",\"b\",\"d\",\"e\"),(\"a\",'b','e','c'))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJNMIJ53lfM3"
      },
      "source": [
        "def create_candidate_1(X):\n",
        "    \"\"\"\n",
        "    create the 1-item candidate,\n",
        "    it's basically creating a frozenset for each unique item\n",
        "    and storing them in a list\n",
        "    \"\"\"\n",
        "    c1 = []\n",
        "    for transaction in X:\n",
        "        for t in transaction:\n",
        "            t = frozenset([t])\n",
        "            if t not in c1:\n",
        "                c1.append(t)\n",
        "    return(c1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51vZihXHlgYL"
      },
      "source": [
        "def apriori(X, min_support):\n",
        "    \"\"\"\n",
        "    pass in the transaction data and the minimum support \n",
        "    threshold to obtain the frequent itemset. Also\n",
        "    store the support for each itemset, they will\n",
        "    be used in the rule generation step\n",
        "    \"\"\"\n",
        "\n",
        "    # the candidate sets for the 1-item is different,\n",
        "    # create them independently from others\n",
        "    c1 = create_candidate_1(X)\n",
        "    freq_item, item_support_dict = create_freq_item(X, c1, min_support = 0.5)\n",
        "    freq_items = [freq_item]\n",
        "    k = 0\n",
        "    while len(freq_items[k]) > 0:\n",
        "        freq_item = freq_items[k]\n",
        "        ck = create_candidate_k(freq_item, k)       \n",
        "        freq_item, item_support = create_freq_item(X, ck, min_support = 0.5)\n",
        "        freq_items.append(freq_item)\n",
        "        item_support_dict.update(item_support)\n",
        "        k += 1\n",
        "        \n",
        "    return freq_items, item_support_dict\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w71-pYTlgar"
      },
      "source": [
        "def create_freq_item(X, ck, min_support):\n",
        "    \"\"\"\n",
        "    filters the candidate with the specified\n",
        "    minimum support\n",
        "    \"\"\"\n",
        "    # loop through the transaction and compute\n",
        "    # the count for each candidate (item)\n",
        "    item_count = {}\n",
        "    for transaction in X:\n",
        "        for item in ck:\n",
        "            if item.issubset(transaction):\n",
        "                if item not in item_count: \n",
        "                    item_count[item] = 1\n",
        "                else: \n",
        "                    item_count[item] += 1    \n",
        "    \n",
        "    n_row = X.shape[0]\n",
        "    freq_item = []\n",
        "    item_support = {}\n",
        "    \n",
        "    # if the support of an item is greater than the \n",
        "    # min_support, then it is considered as frequent\n",
        "    for item in item_count:\n",
        "        support = item_count[item] / n_row\n",
        "        if support >= min_support:\n",
        "            freq_item.append(item)\n",
        "        \n",
        "        item_support[item] = support\n",
        "        \n",
        "    return freq_item, item_support\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8BR6u3olgdB"
      },
      "source": [
        "def create_candidate_k(freq_item, k):\n",
        "    \"\"\"create the list of k-item candidate\"\"\"\n",
        "    ck = []\n",
        "    \n",
        "    # for generating candidate of size two (2-itemset)\n",
        "    if k == 0:\n",
        "        for f1, f2 in combinations(freq_item, 2):\n",
        "            item = f1 | f2 # union of two sets\n",
        "            ck.append(item)\n",
        "    else:    \n",
        "        for f1, f2 in combinations(freq_item, 2):       \n",
        "            # if the two (k+1)-item sets has\n",
        "            # k common elements then they will be\n",
        "            # unioned to be the (k+2)-item candidate\n",
        "            intersection = f1 & f2\n",
        "            if len(intersection) == k:\n",
        "                item = f1 | f2\n",
        "                if item not in ck:\n",
        "                    ck.append(item)\n",
        "    return ck"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUj9ozeRlggZ",
        "outputId": "9fd2f468-7214-47e7-98de-7a5602365132"
      },
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "X = np.array([list(['a','b','c']),\n",
        "              list(['a','b']),\n",
        "              list(['a','b','d']),\n",
        "              list(['b','e']),\n",
        "              list(['b','c','e']),\n",
        "             list(['a','d','e']),\n",
        "             list(['a','c']),\n",
        "              list(['a','b','d']),\n",
        "              list(['c','e']),\n",
        "              list(['a','b','d','e']),\n",
        "              list(['a','b','e','c'])],dtype=object)\n",
        "freq_items, item_support_dict = apriori(X, min_support = 3)\n",
        "freq_items\n",
        "print(item_support_dict)\n",
        "#19BCN7003"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{frozenset({'a'}): 0.7272727272727273, frozenset({'b'}): 0.7272727272727273, frozenset({'c'}): 0.45454545454545453, frozenset({'d'}): 0.36363636363636365, frozenset({'e'}): 0.5454545454545454, frozenset({'a', 'b'}): 0.5454545454545454, frozenset({'e', 'b'}): 0.36363636363636365, frozenset({'a', 'e'}): 0.2727272727272727}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD04zX0J9Zfq"
      },
      "source": [
        "**2)** Develop a python code to provideassociation rules from thegenerated frequent itemsetsin\n",
        "exercise 1with minimum confidence of 80%.[Perform the comparison of your output \n",
        "with predefined packages output carried out in Lab Exercise 8.]*** Do not use any \n",
        "predefined packages such as mlxtend, apyori to apply Apriori algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-vVevbhmfw7",
        "outputId": "eb5416cf-5711-4fc9-a8bb-b2b807bffe92"
      },
      "source": [
        "def create_rules(freq_items, item_support_dict, min_confidence):\n",
        "    \"\"\"\n",
        "    create the association rules, the rules will be a list.\n",
        "    each element is a tuple of size 4, containing rules'\n",
        "    left hand side, right hand side, confidence and lift\n",
        "    \"\"\"\n",
        "    association_rules = []\n",
        "\n",
        "    # for the list that stores the frequent items, loop through\n",
        "    # the second element to the one before the last to generate the rules\n",
        "    # because the last one will be an empty list. It's the stopping criteria\n",
        "    # for the frequent itemset generating process and the first one are all\n",
        "    # single element frequent itemset, which can't perform the set\n",
        "    # operation X -> Y - X\n",
        "    for idx, freq_item in enumerate(freq_items[1:(len(freq_items) - 1)]):\n",
        "        for freq_set in freq_item:\n",
        "            \n",
        "            # start with creating rules for single item on\n",
        "            # the right hand side\n",
        "            subsets = [frozenset([item]) for item in freq_set]\n",
        "            rules, right_hand_side = compute_conf(freq_items, item_support_dict, \n",
        "                                                  freq_set, subsets, min_confidence)\n",
        "            association_rules.extend(rules)\n",
        "            \n",
        "            # starting from 3-itemset, loop through each length item\n",
        "            # to create the rules, as for the while loop condition,\n",
        "            # e.g. suppose you start with a 3-itemset {2, 3, 5} then the \n",
        "            # while loop condition will stop when the right hand side's\n",
        "            # item is of length 2, e.g. [ {2, 3}, {3, 5} ], since this\n",
        "            # will be merged into 3 itemset, making the left hand side\n",
        "            # null when computing the confidence\n",
        "            if idx != 0:\n",
        "                k = 0\n",
        "                while len(right_hand_side[0]) < len(freq_set) - 1:\n",
        "                    ck = create_candidate_k(right_hand_side, k = k)\n",
        "                    rules, right_hand_side = compute_conf(freq_items, item_support_dict,\n",
        "                                                          freq_set, ck, min_confidence)\n",
        "                    association_rules.extend(rules)\n",
        "                    k += 1    \n",
        "    \n",
        "    return association_rules\n",
        "\n",
        "def compute_conf(freq_items, item_support_dict, freq_set, subsets, min_confidence):\n",
        "    \"\"\"\n",
        "    create the rules and returns the rules info and the rules's\n",
        "    right hand side (used for generating the next round of rules) \n",
        "    if it surpasses the minimum confidence threshold\n",
        "    \"\"\"\n",
        "    rules = []\n",
        "    right_hand_side = []\n",
        "    \n",
        "    for rhs in subsets:\n",
        "        # create the left hand side of the rule\n",
        "        # and add the rules if it's greater than\n",
        "        # the confidence threshold\n",
        "        lhs = freq_set - rhs\n",
        "        conf = item_support_dict[freq_set] / item_support_dict[lhs]\n",
        "        if conf >= min_confidence:\n",
        "            lift = conf / item_support_dict[rhs]\n",
        "            rules_info = lhs, rhs, conf, lift\n",
        "            rules.append(rules_info)\n",
        "            right_hand_side.append(rhs)\n",
        "            \n",
        "    return rules, right_hand_side\n",
        "\n",
        "\n",
        "association_rules = create_rules(freq_items, item_support_dict, min_confidence = 0.5)\n",
        "association_rules\n",
        "#19BCN7003"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(frozenset({'b'}), frozenset({'a'}), 0.7499999999999999, 1.0312499999999998),\n",
              " (frozenset({'a'}), frozenset({'b'}), 0.7499999999999999, 1.0312499999999998)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V4kzj_NmfzN",
        "outputId": "a3691a34-d0ec-49ee-d914-55dc931ae739"
      },
      "source": [
        "pip install apriori_python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apriori_python\n",
            "  Downloading apriori_python-1.0.4-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: apriori-python\n",
            "Successfully installed apriori-python-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8tS_iMSmf2q",
        "outputId": "f71bfe65-caf0-439e-939c-9c8b3b316117"
      },
      "source": [
        "from apriori_python import apriori\n",
        "import numpy as np\n",
        "itemSetList = np.array([list(['a','b','c']),\n",
        "              list(['a','b']),\n",
        "              list(['a','b','d']),\n",
        "              list(['b','e']),\n",
        "              list(['b','c','e']),\n",
        "             list(['a','d','e']),\n",
        "             list(['a','c']),\n",
        "              list(['a','b','d']),\n",
        "              list(['c','e']),\n",
        "              list(['a','b','d','e']),\n",
        "              list(['a','b','e','c'])],dtype=object)\n",
        "freqItemSet, rules = apriori(itemSetList, minSup=0.5, minConf=0.5)\n",
        "print(freqItemSet)\n",
        "print(rules)\n",
        "#19BCN7003"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: {frozenset({'a'}), frozenset({'e'}), frozenset({'b'})}, 2: {frozenset({'a', 'b'})}}\n",
            "[[{'a'}, {'b'}, 0.75], [{'b'}, {'a'}, 0.75]]\n"
          ]
        }
      ]
    }
  ]
}